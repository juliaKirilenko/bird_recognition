{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oA79XKe3t-ia"
   },
   "source": [
    "# **Fowl Escapades**\n",
    "#### This notebook shows one of the possible solutions of the 'Fowl Escapades' challenge on Zindi.This solution took 16th place with a Log Loss of 2.18.\n",
    "### **Data used:**\n",
    "#### Test.zip, Train.zip and CSV files (Train.csv, SampleSubmission.csv) from Zindi. All data is available on Zindi: https://zindi.africa/competitions/fowl-escapades/data\n",
    "#### External data was not used.\n",
    "### **Output data:**\n",
    "#### birds_276.csv - features of training dataset\n",
    "#### birds_test_276.csv -  features of test dataset\n",
    "#### model_ens_3_all.h5 - model trained on 100 epochs\n",
    "#### submission_starter_notebook_8.csv - file following the sample submission format with model's predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6HOd8Q40SVR"
   },
   "source": [
    "### All data should be stored in the folder on path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOf-WH3F0sqS"
   },
   "outputs": [],
   "source": [
    "path = \"Birds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVINMQn_BPnG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import csv\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDAXbsmhBVtA"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(path, \"Train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WfSFKytBpTt"
   },
   "outputs": [],
   "source": [
    "# Generate labels for train\n",
    "Y_train = np.array(train['common_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmM7gfas2ZYz"
   },
   "outputs": [],
   "source": [
    "# Preparing paths for training data\n",
    "train['file_name'] = 'Train/'+train['ID']+'.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>common_name</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBMG2C</td>\n",
       "      <td>Ring-necked Dove</td>\n",
       "      <td>Train/MBMG2C.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K8LJSB</td>\n",
       "      <td>Ring-necked Dove</td>\n",
       "      <td>Train/K8LJSB.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OGD9L6</td>\n",
       "      <td>Ring-necked Dove</td>\n",
       "      <td>Train/OGD9L6.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581PCQ</td>\n",
       "      <td>Ring-necked Dove</td>\n",
       "      <td>Train/581PCQ.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P91M1F</td>\n",
       "      <td>Ring-necked Dove</td>\n",
       "      <td>Train/P91M1F.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID       common_name         file_name\n",
       "0  MBMG2C  Ring-necked Dove  Train/MBMG2C.mp3\n",
       "1  K8LJSB  Ring-necked Dove  Train/K8LJSB.mp3\n",
       "2  OGD9L6  Ring-necked Dove  Train/OGD9L6.mp3\n",
       "3  581PCQ  Ring-necked Dove  Train/581PCQ.mp3\n",
       "4  P91M1F  Ring-necked Dove  Train/P91M1F.mp3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4jf-m64Y35fa"
   },
   "source": [
    "## **Feature extraction**\n",
    "#### magnitude - magphase separate a complex-valued spectrogram D (stft) into its magnitude (S) and phase (P) components (65)\n",
    "#### tonnetz - tonal centroid features (6)\n",
    "#### mfcc - Mel-frequency cepstral coefficients (number of MFCCs: 26)\n",
    "#### logmel - a mel-scaled spectrogram (number of mels: 26)\n",
    "#### chroma - a chromagram from a waveform or power spectrogram (12)\n",
    "#### cens - computes the chroma variant “Chroma Energy Normalized” (CENS) (3 - max, min and mean values)\n",
    "#### Total 276 features (mean and std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GqKeiPEk4NXV"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def minMaxNormalize(arr):\n",
    "    mn = np.min(arr)\n",
    "    mx = np.max(arr)\n",
    "    return (arr-mn)/(mx-mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiFWnsy_3MEX"
   },
   "outputs": [],
   "source": [
    "def features_extraction(paths):\n",
    "  X_train = []\n",
    "  for pth in paths:\n",
    "    audio_data, sample_rate = librosa.load(os.path.join(path,pth))\n",
    "\n",
    "    stft = librosa.stft(audio_data, n_fft=128, hop_length=1024)\n",
    "    magnitude, phase = librosa.magphase(stft)\n",
    "\n",
    "    tonnetz = librosa.feature.tonnetz(audio_data)\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(audio_data, n_mfcc = 26, hop_length = 1024, n_fft = 512)\n",
    "\n",
    "    logmel = librosa.feature.melspectrogram(audio_data, hop_length = 1024, n_fft = 512, n_mels=26)\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(audio_data, hop_length = 1024, n_fft = 512)\n",
    "\n",
    "    cens = librosa.feature.chroma_cens(audio_data, hop_length = 1024)\n",
    "    cens_arr = []\n",
    "    cens_mean = cens.mean(axis = 0)\n",
    "    cens_arr.append(max(cens_mean))\n",
    "    cens_arr.append(min(cens_mean))\n",
    "    cens_arr.append(cens_mean.mean(axis=0))\n",
    "    cens_std = cens.std(axis = 0)\n",
    "    cens_arr.append(max(cens_std))\n",
    "    cens_arr.append(min(cens_std))\n",
    "    cens_arr.append(cens_std.mean(axis=0))\n",
    "    cens_arr = np.array(cens_arr)\n",
    "\n",
    "    features_all = np.concatenate((magnitude.mean(axis = 1), magnitude.std(axis = 1), tonnetz.mean(axis = 1), tonnetz.std(axis = 1),\n",
    "                                   mfcc.mean(axis = 1), mfcc.std(axis = 1), minMaxNormalize(logmel.mean(axis = 1)),\n",
    "                                   minMaxNormalize(logmel.std(axis = 1)), chroma.mean(axis = 1), chroma.std(axis = 1), cens_arr), axis = 0)\n",
    "    \n",
    "    X_train.append(features_all)\n",
    "  return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2-DiD4W5nfM"
   },
   "outputs": [],
   "source": [
    "X_train = features_extraction(train['file_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGA4tQ4j6c0v"
   },
   "outputs": [],
   "source": [
    "#X_train = np.array(features_extraction(train['file_name'].values[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPN-7AGCCyRI"
   },
   "outputs": [],
   "source": [
    "# Write train features to csv\n",
    "with open(os.path.join(path, \"birds_276.csv\"), \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZua29VoETMy"
   },
   "outputs": [],
   "source": [
    "# Read train features from csv\n",
    "# X_train = np.array(pd.read_csv(os.path.join(path, \"birds_276.csv\"), header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1857, 276)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gByv-rfFEhvy"
   },
   "outputs": [],
   "source": [
    "# Mix training data\n",
    "n_samples = len(Y_train)\n",
    "order = np.array(range(n_samples))\n",
    "np.random.shuffle(order)\n",
    "X_train_unorder = X_train[order]\n",
    "Y_train_unorder = Y_train[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idBUVqHDFBMZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfYm2tLeFHlp"
   },
   "outputs": [],
   "source": [
    "# Transform labels to arrays of size 40: [0, 0, 1, ..., 0, 0]\n",
    "lb = LabelEncoder()\n",
    "Y_train_unorder = np_utils.to_categorical(lb.fit_transform(Y_train_unorder))\n",
    "# Split data on training and validation data\n",
    "# X_train_new, X_validation, y_train_new, y_validation = train_test_split(X_train_unorder, Y_train_unorder, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aS589zhwF1cw"
   },
   "outputs": [],
   "source": [
    "# Reshape training data\n",
    "X_train_unorder = np.array(X_train_unorder).reshape(X_train_unorder.shape[0], X_train_unorder.shape[1], 1)\n",
    "# X_train_new = np.array(X_train_new).reshape(X_train_new.shape[0], X_train_new.shape[1], 1)\n",
    "# X_validation = np.array(X_validation).reshape(X_validation.shape[0], X_validation.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrDmas_fGCfD"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import MaxPooling1D, Conv1D, GlobalAveragePooling1D, Flatten, Concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import load_model, Model, save_model\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "import keras.layers as L\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EC3z0nNgDbll",
    "outputId": "1ece3d45-2b30-4869-9f74-7afa41b4911b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 142, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 126, 64)      256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 140, 128)     512         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 126, 64)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 140, 128)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 63, 64)       0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 46, 128)      0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 61, 32)       6176        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 44, 64)       24640       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 61, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 44, 64)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 30, 32)       0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 22, 64)       0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 28, 16)       1552        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 20, 16)       3088        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 16)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 20, 16)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 14, 16)       0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 10, 16)       0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 9, 8)         776         max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 4, 2)         8           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 5, 8)         776         max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 9, 8)         0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 2)         0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 5, 8)         0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 72)           0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8)            0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 40)           0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 120)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120)          14520       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 40)           4840        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,144\n",
      "Trainable params: 57,144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Last model on submit\n",
    "inputs1 = L.Input((128,1))\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs1)\n",
    "conv1 = Dropout(0.25)(conv1)\n",
    "conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(conv1)\n",
    "conv1 = Dropout(0.25)(conv1)\n",
    "conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv1 = Conv1D(filters=16, kernel_size=3, activation='relu')(conv1)\n",
    "conv1 = Dropout(0.25)(conv1)\n",
    "conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv1 = Conv1D(filters=8, kernel_size=6, activation='relu')(conv1)\n",
    "conv1 = Dropout(0.25)(conv1)\n",
    "#conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv1 = Flatten()(conv1)\n",
    "\t# head 2\n",
    "inputs2 = L.Input((6,1))\n",
    "conv2 = Conv1D(filters=2, kernel_size=3, activation='relu')(inputs2)\n",
    "conv2 = Dropout(0.15)(conv2)\n",
    "#conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "conv2 = Flatten()(conv2)\n",
    "\t# head 3\n",
    "inputs3 = L.Input((142,1))\n",
    "conv3 = Conv1D(filters=128, kernel_size=3, activation='relu')(inputs3)\n",
    "conv3 = Dropout(0.15)(conv3)\n",
    "conv3 = MaxPooling1D(pool_size=3)(conv3)\n",
    "conv3 = Conv1D(filters=64, kernel_size=3, activation='relu')(conv3)\n",
    "conv3 = Dropout(0.15)(conv3)\n",
    "conv3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "conv3 = Conv1D(filters=16, kernel_size=3, activation='relu')(conv3)\n",
    "conv3 = Dropout(0.15)(conv3)\n",
    "conv3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "conv3 = Conv1D(filters=8, kernel_size=6, activation='relu')(conv3)\n",
    "conv3 = Dropout(0.15)(conv3)\n",
    "#conv3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "conv3 = Flatten()(conv3)\n",
    "\t# merge\n",
    "merged = Concatenate(axis=1)([conv1, conv2, conv3])\n",
    "\t# interpretation\n",
    "dense1 = Dense(120, activation='relu')(merged)\n",
    "outputs = Dense(40, activation='softmax')(dense1)\n",
    "model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZRcQ37qn_mcg",
    "outputId": "c8515925-fe8a-4e7f-94ca-682a391aea3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1485 samples, validate on 372 samples\n",
      "Epoch 1/100\n",
      "1485/1485 [==============================] - 2s 2ms/step - loss: 3.7577 - accuracy: 0.0404 - val_loss: 3.6537 - val_accuracy: 0.0376\n",
      "Epoch 2/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 3.5942 - accuracy: 0.0747 - val_loss: 3.5614 - val_accuracy: 0.0699\n",
      "Epoch 3/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 3.4490 - accuracy: 0.1037 - val_loss: 3.4007 - val_accuracy: 0.1344\n",
      "Epoch 4/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 3.2877 - accuracy: 0.1360 - val_loss: 3.2096 - val_accuracy: 0.1613\n",
      "Epoch 5/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 3.1158 - accuracy: 0.1522 - val_loss: 3.0910 - val_accuracy: 0.1855\n",
      "Epoch 6/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.9753 - accuracy: 0.1737 - val_loss: 2.9653 - val_accuracy: 0.1962\n",
      "Epoch 7/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.8960 - accuracy: 0.1886 - val_loss: 2.9039 - val_accuracy: 0.2446\n",
      "Epoch 8/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.8203 - accuracy: 0.1906 - val_loss: 2.8270 - val_accuracy: 0.2581\n",
      "Epoch 9/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.7169 - accuracy: 0.2128 - val_loss: 2.7743 - val_accuracy: 0.2419\n",
      "Epoch 10/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.7026 - accuracy: 0.2168 - val_loss: 2.7177 - val_accuracy: 0.2581\n",
      "Epoch 11/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.6415 - accuracy: 0.2182 - val_loss: 2.6779 - val_accuracy: 0.2446\n",
      "Epoch 12/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.6547 - accuracy: 0.2236 - val_loss: 2.6964 - val_accuracy: 0.2688\n",
      "Epoch 13/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.5944 - accuracy: 0.2478 - val_loss: 2.6256 - val_accuracy: 0.3011\n",
      "Epoch 14/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.5538 - accuracy: 0.2586 - val_loss: 2.6162 - val_accuracy: 0.3038\n",
      "Epoch 15/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.5458 - accuracy: 0.2465 - val_loss: 2.5489 - val_accuracy: 0.3038\n",
      "Epoch 16/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.5256 - accuracy: 0.2586 - val_loss: 2.5312 - val_accuracy: 0.3280\n",
      "Epoch 17/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.4672 - accuracy: 0.2707 - val_loss: 2.5036 - val_accuracy: 0.3145\n",
      "Epoch 18/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.4662 - accuracy: 0.2707 - val_loss: 2.5352 - val_accuracy: 0.3522\n",
      "Epoch 19/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.4013 - accuracy: 0.2949 - val_loss: 2.4989 - val_accuracy: 0.3280\n",
      "Epoch 20/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.4066 - accuracy: 0.2835 - val_loss: 2.4767 - val_accuracy: 0.3522\n",
      "Epoch 21/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.3927 - accuracy: 0.2869 - val_loss: 2.4756 - val_accuracy: 0.3495\n",
      "Epoch 22/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.3396 - accuracy: 0.3138 - val_loss: 2.4359 - val_accuracy: 0.3683\n",
      "Epoch 23/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.3412 - accuracy: 0.3010 - val_loss: 2.4113 - val_accuracy: 0.3548\n",
      "Epoch 24/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.3320 - accuracy: 0.3024 - val_loss: 2.4336 - val_accuracy: 0.3333\n",
      "Epoch 25/100\n",
      "1485/1485 [==============================] - 3s 2ms/step - loss: 2.3208 - accuracy: 0.3077 - val_loss: 2.3897 - val_accuracy: 0.3575\n",
      "Epoch 26/100\n",
      "1485/1485 [==============================] - 3s 2ms/step - loss: 2.2685 - accuracy: 0.3226 - val_loss: 2.3781 - val_accuracy: 0.3683\n",
      "Epoch 27/100\n",
      "1485/1485 [==============================] - 3s 2ms/step - loss: 2.2491 - accuracy: 0.3380 - val_loss: 2.4016 - val_accuracy: 0.3360\n",
      "Epoch 28/100\n",
      "1485/1485 [==============================] - 3s 2ms/step - loss: 2.2598 - accuracy: 0.3300 - val_loss: 2.3957 - val_accuracy: 0.3790\n",
      "Epoch 29/100\n",
      "1485/1485 [==============================] - 3s 2ms/step - loss: 2.1981 - accuracy: 0.3374 - val_loss: 2.3160 - val_accuracy: 0.3683\n",
      "Epoch 30/100\n",
      "1485/1485 [==============================] - 2s 2ms/step - loss: 2.1933 - accuracy: 0.3448 - val_loss: 2.3383 - val_accuracy: 0.3710\n",
      "Epoch 31/100\n",
      "1485/1485 [==============================] - 2s 2ms/step - loss: 2.1806 - accuracy: 0.3434 - val_loss: 2.3198 - val_accuracy: 0.3629\n",
      "Epoch 32/100\n",
      "1485/1485 [==============================] - 2s 2ms/step - loss: 2.1735 - accuracy: 0.3481 - val_loss: 2.3013 - val_accuracy: 0.4032\n",
      "Epoch 33/100\n",
      "1485/1485 [==============================] - 2s 2ms/step - loss: 2.1594 - accuracy: 0.3421 - val_loss: 2.3310 - val_accuracy: 0.3414\n",
      "Epoch 34/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.1446 - accuracy: 0.3650 - val_loss: 2.2892 - val_accuracy: 0.3656\n",
      "Epoch 35/100\n",
      "1485/1485 [==============================] - 2s 2ms/step - loss: 2.1442 - accuracy: 0.3596 - val_loss: 2.3008 - val_accuracy: 0.3763\n",
      "Epoch 36/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.0741 - accuracy: 0.3731 - val_loss: 2.2644 - val_accuracy: 0.3898\n",
      "Epoch 37/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.0542 - accuracy: 0.3636 - val_loss: 2.2815 - val_accuracy: 0.3629\n",
      "Epoch 38/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.1099 - accuracy: 0.3535 - val_loss: 2.2942 - val_accuracy: 0.3737\n",
      "Epoch 39/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.0600 - accuracy: 0.3771 - val_loss: 2.2132 - val_accuracy: 0.4005\n",
      "Epoch 40/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.0380 - accuracy: 0.3751 - val_loss: 2.2226 - val_accuracy: 0.3790\n",
      "Epoch 41/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.0459 - accuracy: 0.3697 - val_loss: 2.2597 - val_accuracy: 0.3952\n",
      "Epoch 42/100\n",
      "1485/1485 [==============================] - 2s 2ms/step - loss: 2.0132 - accuracy: 0.3973 - val_loss: 2.2160 - val_accuracy: 0.4005\n",
      "Epoch 43/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.0203 - accuracy: 0.3791 - val_loss: 2.2717 - val_accuracy: 0.3495\n",
      "Epoch 44/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 2.0121 - accuracy: 0.3993 - val_loss: 2.2283 - val_accuracy: 0.3925\n",
      "Epoch 45/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.9585 - accuracy: 0.3926 - val_loss: 2.2062 - val_accuracy: 0.3790\n",
      "Epoch 46/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.9567 - accuracy: 0.4007 - val_loss: 2.2059 - val_accuracy: 0.3925\n",
      "Epoch 47/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.9277 - accuracy: 0.4094 - val_loss: 2.1738 - val_accuracy: 0.3978\n",
      "Epoch 48/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.9254 - accuracy: 0.4114 - val_loss: 2.2400 - val_accuracy: 0.3522\n",
      "Epoch 49/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.9231 - accuracy: 0.4202 - val_loss: 2.2466 - val_accuracy: 0.3468\n",
      "Epoch 50/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.9077 - accuracy: 0.4209 - val_loss: 2.2473 - val_accuracy: 0.3737\n",
      "Epoch 51/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8987 - accuracy: 0.4182 - val_loss: 2.2016 - val_accuracy: 0.3898\n",
      "Epoch 52/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.9035 - accuracy: 0.4310 - val_loss: 2.1763 - val_accuracy: 0.3898\n",
      "Epoch 53/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8865 - accuracy: 0.4114 - val_loss: 2.1836 - val_accuracy: 0.4059\n",
      "Epoch 54/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8840 - accuracy: 0.4276 - val_loss: 2.1906 - val_accuracy: 0.3737\n",
      "Epoch 55/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8526 - accuracy: 0.4202 - val_loss: 2.1764 - val_accuracy: 0.3763\n",
      "Epoch 56/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8702 - accuracy: 0.4141 - val_loss: 2.1784 - val_accuracy: 0.3790\n",
      "Epoch 57/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8724 - accuracy: 0.4350 - val_loss: 2.1683 - val_accuracy: 0.4140\n",
      "Epoch 58/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8502 - accuracy: 0.4141 - val_loss: 2.1621 - val_accuracy: 0.4059\n",
      "Epoch 59/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8513 - accuracy: 0.4296 - val_loss: 2.1729 - val_accuracy: 0.3898\n",
      "Epoch 60/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7881 - accuracy: 0.4471 - val_loss: 2.1564 - val_accuracy: 0.4059\n",
      "Epoch 61/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8146 - accuracy: 0.4391 - val_loss: 2.1758 - val_accuracy: 0.4086\n",
      "Epoch 62/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7706 - accuracy: 0.4552 - val_loss: 2.1758 - val_accuracy: 0.3763\n",
      "Epoch 63/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.8155 - accuracy: 0.4458 - val_loss: 2.1887 - val_accuracy: 0.3844\n",
      "Epoch 64/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7773 - accuracy: 0.4539 - val_loss: 2.1506 - val_accuracy: 0.3817\n",
      "Epoch 65/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7478 - accuracy: 0.4532 - val_loss: 2.1385 - val_accuracy: 0.4167\n",
      "Epoch 66/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7184 - accuracy: 0.4660 - val_loss: 2.1491 - val_accuracy: 0.3737\n",
      "Epoch 67/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7223 - accuracy: 0.4545 - val_loss: 2.1593 - val_accuracy: 0.3763\n",
      "Epoch 68/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6861 - accuracy: 0.4788 - val_loss: 2.1476 - val_accuracy: 0.3844\n",
      "Epoch 69/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7017 - accuracy: 0.4532 - val_loss: 2.1113 - val_accuracy: 0.4086\n",
      "Epoch 70/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6535 - accuracy: 0.4882 - val_loss: 2.1464 - val_accuracy: 0.3871\n",
      "Epoch 71/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6552 - accuracy: 0.4815 - val_loss: 2.1352 - val_accuracy: 0.3978\n",
      "Epoch 72/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6704 - accuracy: 0.4606 - val_loss: 2.1533 - val_accuracy: 0.3952\n",
      "Epoch 73/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6450 - accuracy: 0.4869 - val_loss: 2.1394 - val_accuracy: 0.4167\n",
      "Epoch 74/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.7002 - accuracy: 0.4552 - val_loss: 2.1887 - val_accuracy: 0.3763\n",
      "Epoch 75/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6676 - accuracy: 0.4828 - val_loss: 2.1686 - val_accuracy: 0.3844\n",
      "Epoch 76/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6783 - accuracy: 0.4768 - val_loss: 2.1330 - val_accuracy: 0.3844\n",
      "Epoch 77/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6676 - accuracy: 0.4875 - val_loss: 2.1046 - val_accuracy: 0.4382\n",
      "Epoch 78/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6234 - accuracy: 0.4855 - val_loss: 2.1636 - val_accuracy: 0.4005\n",
      "Epoch 79/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6538 - accuracy: 0.4862 - val_loss: 2.1680 - val_accuracy: 0.3871\n",
      "Epoch 80/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6088 - accuracy: 0.4761 - val_loss: 2.1334 - val_accuracy: 0.4113\n",
      "Epoch 81/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5956 - accuracy: 0.4929 - val_loss: 2.1422 - val_accuracy: 0.4194\n",
      "Epoch 82/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6180 - accuracy: 0.4943 - val_loss: 2.1599 - val_accuracy: 0.3763\n",
      "Epoch 83/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5694 - accuracy: 0.4976 - val_loss: 2.1464 - val_accuracy: 0.3844\n",
      "Epoch 84/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5817 - accuracy: 0.5118 - val_loss: 2.1277 - val_accuracy: 0.4140\n",
      "Epoch 85/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5312 - accuracy: 0.5111 - val_loss: 2.1376 - val_accuracy: 0.3790\n",
      "Epoch 86/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.6044 - accuracy: 0.4889 - val_loss: 2.1664 - val_accuracy: 0.3871\n",
      "Epoch 87/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5245 - accuracy: 0.5306 - val_loss: 2.1138 - val_accuracy: 0.4005\n",
      "Epoch 88/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5376 - accuracy: 0.5051 - val_loss: 2.1728 - val_accuracy: 0.3763\n",
      "Epoch 89/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5492 - accuracy: 0.5044 - val_loss: 2.1161 - val_accuracy: 0.4059\n",
      "Epoch 90/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5455 - accuracy: 0.5246 - val_loss: 2.0972 - val_accuracy: 0.4167\n",
      "Epoch 91/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5140 - accuracy: 0.5192 - val_loss: 2.1050 - val_accuracy: 0.4113\n",
      "Epoch 92/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5126 - accuracy: 0.5084 - val_loss: 2.1013 - val_accuracy: 0.4220\n",
      "Epoch 93/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.4736 - accuracy: 0.5394 - val_loss: 2.0979 - val_accuracy: 0.4301\n",
      "Epoch 94/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.5267 - accuracy: 0.5158 - val_loss: 2.0899 - val_accuracy: 0.4301\n",
      "Epoch 95/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.4992 - accuracy: 0.5293 - val_loss: 2.1314 - val_accuracy: 0.3978\n",
      "Epoch 96/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.4811 - accuracy: 0.5380 - val_loss: 2.1239 - val_accuracy: 0.4113\n",
      "Epoch 97/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.4638 - accuracy: 0.5145 - val_loss: 2.1237 - val_accuracy: 0.4113\n",
      "Epoch 98/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.4777 - accuracy: 0.5347 - val_loss: 2.1540 - val_accuracy: 0.3978\n",
      "Epoch 99/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.4817 - accuracy: 0.5219 - val_loss: 2.1440 - val_accuracy: 0.4167\n",
      "Epoch 100/100\n",
      "1485/1485 [==============================] - 2s 1ms/step - loss: 1.4286 - accuracy: 0.5475 - val_loss: 2.1393 - val_accuracy: 0.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa3cd0ffda0>"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with validation data\n",
    "#model.fit([X_train_new[:,:128], X_train_new[:,128:134], X_train_new[:,134:276]], y_train_new, batch_size=64, epochs=100,validation_data=([X_validation[:,:128], X_validation[:,128:134], X_validation[:,134:276]],y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "d69kHEu7wjH8",
    "outputId": "f96b6213-54aa-4a9f-f131-29d212c4208a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 3.8680 - accuracy: 0.0350\n",
      "Epoch 2/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 3.5743 - accuracy: 0.0749\n",
      "Epoch 3/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 3.4100 - accuracy: 0.1325\n",
      "Epoch 4/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 3.2366 - accuracy: 0.1481\n",
      "Epoch 5/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 3.0814 - accuracy: 0.1605\n",
      "Epoch 6/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 3.0125 - accuracy: 0.1788\n",
      "Epoch 7/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.9031 - accuracy: 0.1955\n",
      "Epoch 8/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.7883 - accuracy: 0.2132\n",
      "Epoch 9/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.7256 - accuracy: 0.2246\n",
      "Epoch 10/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.6808 - accuracy: 0.2267\n",
      "Epoch 11/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.6498 - accuracy: 0.2229\n",
      "Epoch 12/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.6372 - accuracy: 0.2359\n",
      "Epoch 13/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.5604 - accuracy: 0.2606\n",
      "Epoch 14/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.5668 - accuracy: 0.2553\n",
      "Epoch 15/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.5497 - accuracy: 0.2531\n",
      "Epoch 16/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.4978 - accuracy: 0.2666\n",
      "Epoch 17/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.4762 - accuracy: 0.2682\n",
      "Epoch 18/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.4614 - accuracy: 0.2714\n",
      "Epoch 19/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.4183 - accuracy: 0.2892\n",
      "Epoch 20/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.4184 - accuracy: 0.2978\n",
      "Epoch 21/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3827 - accuracy: 0.2935\n",
      "Epoch 22/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3927 - accuracy: 0.2800\n",
      "Epoch 23/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3991 - accuracy: 0.2892\n",
      "Epoch 24/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3593 - accuracy: 0.2935\n",
      "Epoch 25/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3167 - accuracy: 0.3021\n",
      "Epoch 26/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3182 - accuracy: 0.3161\n",
      "Epoch 27/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3055 - accuracy: 0.3026\n",
      "Epoch 28/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3541 - accuracy: 0.2983\n",
      "Epoch 29/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.3181 - accuracy: 0.3016\n",
      "Epoch 30/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.2814 - accuracy: 0.3188\n",
      "Epoch 31/140\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 2.3128 - accuracy: 0.3139\n",
      "Epoch 32/140\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 2.2340 - accuracy: 0.3360\n",
      "Epoch 33/140\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 2.2564 - accuracy: 0.3328\n",
      "Epoch 34/140\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 2.2046 - accuracy: 0.3419\n",
      "Epoch 35/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.2029 - accuracy: 0.3398\n",
      "Epoch 36/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.1816 - accuracy: 0.3473\n",
      "Epoch 37/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.2294 - accuracy: 0.3376\n",
      "Epoch 38/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.1877 - accuracy: 0.3586\n",
      "Epoch 39/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.1959 - accuracy: 0.3371\n",
      "Epoch 40/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.1847 - accuracy: 0.3667\n",
      "Epoch 41/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.2043 - accuracy: 0.3339\n",
      "Epoch 42/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.1521 - accuracy: 0.3425\n",
      "Epoch 43/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.1061 - accuracy: 0.3678\n",
      "Epoch 44/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0811 - accuracy: 0.3856\n",
      "Epoch 45/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0893 - accuracy: 0.3721\n",
      "Epoch 46/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0598 - accuracy: 0.3737\n",
      "Epoch 47/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.1412 - accuracy: 0.3608\n",
      "Epoch 48/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0834 - accuracy: 0.3689\n",
      "Epoch 49/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0577 - accuracy: 0.3743\n",
      "Epoch 50/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0626 - accuracy: 0.3705\n",
      "Epoch 51/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0456 - accuracy: 0.3802\n",
      "Epoch 52/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0415 - accuracy: 0.3748\n",
      "Epoch 53/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0504 - accuracy: 0.3700\n",
      "Epoch 54/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0957 - accuracy: 0.3721\n",
      "Epoch 55/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 2.0314 - accuracy: 0.3856\n",
      "Epoch 56/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9948 - accuracy: 0.3963\n",
      "Epoch 57/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9679 - accuracy: 0.3915\n",
      "Epoch 58/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9489 - accuracy: 0.4071\n",
      "Epoch 59/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9569 - accuracy: 0.4001\n",
      "Epoch 60/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9885 - accuracy: 0.3834\n",
      "Epoch 61/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9344 - accuracy: 0.4200\n",
      "Epoch 62/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9502 - accuracy: 0.3996\n",
      "Epoch 63/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9245 - accuracy: 0.4076\n",
      "Epoch 64/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9309 - accuracy: 0.4082\n",
      "Epoch 65/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9322 - accuracy: 0.4168\n",
      "Epoch 66/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9300 - accuracy: 0.4114\n",
      "Epoch 67/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9417 - accuracy: 0.4195\n",
      "Epoch 68/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9055 - accuracy: 0.4190\n",
      "Epoch 69/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9872 - accuracy: 0.4017\n",
      "Epoch 70/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9798 - accuracy: 0.4012\n",
      "Epoch 71/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.9248 - accuracy: 0.4060\n",
      "Epoch 72/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8791 - accuracy: 0.4303\n",
      "Epoch 73/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8848 - accuracy: 0.4093\n",
      "Epoch 74/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8317 - accuracy: 0.4330\n",
      "Epoch 75/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8129 - accuracy: 0.4292\n",
      "Epoch 76/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8219 - accuracy: 0.4437\n",
      "Epoch 77/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8652 - accuracy: 0.4319\n",
      "Epoch 78/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8322 - accuracy: 0.4303\n",
      "Epoch 79/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8428 - accuracy: 0.4308\n",
      "Epoch 80/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8015 - accuracy: 0.4416\n",
      "Epoch 81/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8200 - accuracy: 0.4426\n",
      "Epoch 82/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.8184 - accuracy: 0.4523\n",
      "Epoch 83/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7803 - accuracy: 0.4572\n",
      "Epoch 84/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7524 - accuracy: 0.4507\n",
      "Epoch 85/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7503 - accuracy: 0.4448\n",
      "Epoch 86/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7494 - accuracy: 0.4604\n",
      "Epoch 87/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7882 - accuracy: 0.4362\n",
      "Epoch 88/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7336 - accuracy: 0.4717\n",
      "Epoch 89/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6858 - accuracy: 0.4755\n",
      "Epoch 90/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7541 - accuracy: 0.4604\n",
      "Epoch 91/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6770 - accuracy: 0.4572\n",
      "Epoch 92/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6790 - accuracy: 0.4647\n",
      "Epoch 93/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6669 - accuracy: 0.4820\n",
      "Epoch 94/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6814 - accuracy: 0.4820\n",
      "Epoch 95/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6349 - accuracy: 0.4814\n",
      "Epoch 96/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6281 - accuracy: 0.4895\n",
      "Epoch 97/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6330 - accuracy: 0.5003\n",
      "Epoch 98/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6669 - accuracy: 0.4809\n",
      "Epoch 99/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6551 - accuracy: 0.4793\n",
      "Epoch 100/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6243 - accuracy: 0.4949\n",
      "Epoch 101/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6472 - accuracy: 0.4820\n",
      "Epoch 102/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6705 - accuracy: 0.4782\n",
      "Epoch 103/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6485 - accuracy: 0.4825\n",
      "Epoch 104/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6535 - accuracy: 0.5003\n",
      "Epoch 105/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6196 - accuracy: 0.4857\n",
      "Epoch 106/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6048 - accuracy: 0.4943\n",
      "Epoch 107/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6660 - accuracy: 0.4976\n",
      "Epoch 108/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6552 - accuracy: 0.5019\n",
      "Epoch 109/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6745 - accuracy: 0.4669\n",
      "Epoch 110/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5898 - accuracy: 0.5057\n",
      "Epoch 111/140\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.6268 - accuracy: 0.4830\n",
      "Epoch 112/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6011 - accuracy: 0.4852\n",
      "Epoch 113/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6890 - accuracy: 0.4685\n",
      "Epoch 114/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5721 - accuracy: 0.4981\n",
      "Epoch 115/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5937 - accuracy: 0.4922\n",
      "Epoch 116/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6730 - accuracy: 0.4701\n",
      "Epoch 117/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5182 - accuracy: 0.5304\n",
      "Epoch 118/140\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.6481 - accuracy: 0.4949\n",
      "Epoch 119/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5943 - accuracy: 0.5013\n",
      "Epoch 120/140\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.5286 - accuracy: 0.5100\n",
      "Epoch 121/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5413 - accuracy: 0.5229\n",
      "Epoch 122/140\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.5842 - accuracy: 0.5013\n",
      "Epoch 123/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5161 - accuracy: 0.5229\n",
      "Epoch 124/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.6653 - accuracy: 0.4701\n",
      "Epoch 125/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5074 - accuracy: 0.5159\n",
      "Epoch 126/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4725 - accuracy: 0.5374\n",
      "Epoch 127/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5471 - accuracy: 0.5304\n",
      "Epoch 128/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5371 - accuracy: 0.5245\n",
      "Epoch 129/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4474 - accuracy: 0.5547\n",
      "Epoch 130/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5063 - accuracy: 0.5207\n",
      "Epoch 131/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4957 - accuracy: 0.5234\n",
      "Epoch 132/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4875 - accuracy: 0.5164\n",
      "Epoch 133/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4937 - accuracy: 0.5299\n",
      "Epoch 134/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5166 - accuracy: 0.5272\n",
      "Epoch 135/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4117 - accuracy: 0.5514\n",
      "Epoch 136/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4509 - accuracy: 0.5385\n",
      "Epoch 137/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4513 - accuracy: 0.5460\n",
      "Epoch 138/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4112 - accuracy: 0.5450\n",
      "Epoch 139/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4881 - accuracy: 0.5358\n",
      "Epoch 140/140\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4388 - accuracy: 0.5272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa3c4d80470>"
      ]
     },
     "execution_count": 247,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit([X_train_unorder[:,:128], X_train_unorder[:,128:134], X_train_unorder[:,134:276]], Y_train_unorder, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3z__d4gfJGxb"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(os.path.join(path,'model_ens_3_all.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IV2iIbZmyLjB"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model = load_model(os.path.join(path,'model_ens_3_all.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxF9k9Bs_NZi"
   },
   "outputs": [],
   "source": [
    "# Preparing paths for test data\n",
    "sub = pd.read_csv(os.path.join(path, \"SampleSubmission.csv\"))\n",
    "sub['file_name'] = 'Test/'+sub['ID']+'.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZD9Wy4OOAEgO"
   },
   "outputs": [],
   "source": [
    "X_test = features_extraction(sub['file_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = np.array(features_extraction(sub['file_name'].values[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQJdhocy_Iwg"
   },
   "outputs": [],
   "source": [
    "# Write test features to csv\n",
    "with open(os.path.join(path, \"birds_test_276.csv\"), \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDnxnPrS-ox_"
   },
   "outputs": [],
   "source": [
    "# Read test features from csv\n",
    "# X_test = np.array(pd.read_csv(os.path.join(path, \"birds_test_276.csv\"), header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5W2Dfi-Tyrh"
   },
   "outputs": [],
   "source": [
    "# Reshape test data\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WP7w4rET5x7"
   },
   "outputs": [],
   "source": [
    "# Predict labels\n",
    "Y_preds = model.predict([X_test[:,:128], X_test[:,128:134], X_test[:,134:276]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1eAiIov3UvdK"
   },
   "outputs": [],
   "source": [
    "# Transform probabilities to sample submission format\n",
    "birds = sub.columns[1:41]\n",
    "birdsn = lb.fit_transform(birds)\n",
    "\n",
    "for ind, b in enumerate(birds):\n",
    "  sub[b] = Y_preds[:, birdsn[ind]]\n",
    "\n",
    "cols = ['ID']\n",
    "for b in birds:\n",
    "  cols.append(b)\n",
    "\n",
    "ss = sub[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZUH2Q7lVyYA"
   },
   "outputs": [],
   "source": [
    "# Write model's predicted probabilities to csv\n",
    "ss.to_csv(os.path.join(path,'submission_starter_notebook_8.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Birds_train_and_test_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
